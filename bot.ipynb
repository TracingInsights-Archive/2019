{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi requests pandas lxml fastf1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "fastf1.Cache.enable_cache(\"cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australian Grand Prix', 'Bahrain Grand Prix', 'Chinese Grand Prix', 'Azerbaijan Grand Prix', 'Spanish Grand Prix', 'Monaco Grand Prix', 'Canadian Grand Prix', 'French Grand Prix', 'Austrian Grand Prix', 'British Grand Prix', 'German Grand Prix', 'Hungarian Grand Prix', 'Belgian Grand Prix', 'Italian Grand Prix', 'Singapore Grand Prix', 'Russian Grand Prix', 'Japanese Grand Prix', 'Mexican Grand Prix', 'United States Grand Prix', 'Brazilian Grand Prix', 'Abu Dhabi Grand Prix']\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import fastf1\n",
    "def events_available(year: int) -> any:\n",
    "    # get events available for a given year\n",
    "    data = utils.LatestData(year)\n",
    "    events = data.get_events()\n",
    "    return events\n",
    "\n",
    "events = events_available(YEAR)\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sessions_available(year: int, event: str | int) -> any:\n",
    "    # get sessions available for a given year and event\n",
    "    event = str(event)\n",
    "    data = utils.LatestData(year)\n",
    "    sessions = data.get_sessions(event)\n",
    "    return sessions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists for Australian Grand Prix: /workspaces/2019/Australian Grand Prix\n",
      "Folder already exists for Bahrain Grand Prix: /workspaces/2019/Bahrain Grand Prix\n",
      "Folder already exists for Chinese Grand Prix: /workspaces/2019/Chinese Grand Prix\n",
      "Folder already exists for Azerbaijan Grand Prix: /workspaces/2019/Azerbaijan Grand Prix\n",
      "Folder already exists for Spanish Grand Prix: /workspaces/2019/Spanish Grand Prix\n",
      "Folder already exists for Monaco Grand Prix: /workspaces/2019/Monaco Grand Prix\n",
      "Folder already exists for Canadian Grand Prix: /workspaces/2019/Canadian Grand Prix\n",
      "Folder already exists for French Grand Prix: /workspaces/2019/French Grand Prix\n",
      "Folder already exists for Austrian Grand Prix: /workspaces/2019/Austrian Grand Prix\n",
      "Folder already exists for British Grand Prix: /workspaces/2019/British Grand Prix\n",
      "Folder already exists for German Grand Prix: /workspaces/2019/German Grand Prix\n",
      "Folder already exists for Hungarian Grand Prix: /workspaces/2019/Hungarian Grand Prix\n",
      "Folder already exists for Belgian Grand Prix: /workspaces/2019/Belgian Grand Prix\n",
      "Folder already exists for Italian Grand Prix: /workspaces/2019/Italian Grand Prix\n",
      "Folder already exists for Singapore Grand Prix: /workspaces/2019/Singapore Grand Prix\n",
      "Folder already exists for Russian Grand Prix: /workspaces/2019/Russian Grand Prix\n",
      "Folder already exists for Japanese Grand Prix: /workspaces/2019/Japanese Grand Prix\n",
      "Folder already exists for Mexican Grand Prix: /workspaces/2019/Mexican Grand Prix\n",
      "Folder already exists for United States Grand Prix: /workspaces/2019/United States Grand Prix\n",
      "Folder already exists for Brazilian Grand Prix: /workspaces/2019/Brazilian Grand Prix\n",
      "Folder already exists for Abu Dhabi Grand Prix: /workspaces/2019/Abu Dhabi Grand Prix\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Your list of events\n",
    "events_list = events\n",
    "\n",
    "# Create a folder for each event in the current working directory\n",
    "for event in events_list:\n",
    "    event_directory = os.path.join(os.getcwd(), event)\n",
    "\n",
    "    # Check if the folder already exists before creating it\n",
    "    if not os.path.exists(event_directory):\n",
    "        os.makedirs(event_directory)\n",
    "        print(f\"Folder created for {event}: {event_directory}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists for {event}: {event_directory}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_drivers(year: int, event: str | int, session: str) -> any:\n",
    "    # get drivers available for a given year, event and session\n",
    "    import fastf1\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=True, weather=False, messages=False)\n",
    "\n",
    "    laps = f1session.laps\n",
    "    team_colors = utils.team_colors(year)\n",
    "    # add team_colors dict to laps on Team column\n",
    "    laps[\"color\"] = laps[\"Team\"].map(team_colors)\n",
    "\n",
    "    unique_drivers = laps[\"Driver\"].unique()\n",
    "\n",
    "    drivers = [\n",
    "        {\n",
    "\n",
    "            \"driver\": driver,\n",
    "            \"team\": laps[laps.Driver == driver].Team.iloc[0],\n",
    "        }\n",
    "        for driver in unique_drivers\n",
    "    ]\n",
    "\n",
    "    return  {\"drivers\": drivers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists for Australian Grand Prix: /workspaces/2019/Australian Grand Prix\n",
      "Folder already exists for Australian Grand Prix - Practice 1: /workspaces/2019/Australian Grand Prix/Practice 1\n",
      "Folder already exists for Australian Grand Prix - Practice 2: /workspaces/2019/Australian Grand Prix/Practice 2\n",
      "Folder already exists for Australian Grand Prix - Practice 3: /workspaces/2019/Australian Grand Prix/Practice 3\n",
      "Folder already exists for Australian Grand Prix - Qualifying: /workspaces/2019/Australian Grand Prix/Qualifying\n",
      "Folder already exists for Australian Grand Prix - Race: /workspaces/2019/Australian Grand Prix/Race\n",
      "Folder already exists for Bahrain Grand Prix: /workspaces/2019/Bahrain Grand Prix\n",
      "Folder already exists for Bahrain Grand Prix - Practice 1: /workspaces/2019/Bahrain Grand Prix/Practice 1\n",
      "Folder already exists for Bahrain Grand Prix - Practice 2: /workspaces/2019/Bahrain Grand Prix/Practice 2\n",
      "Folder already exists for Bahrain Grand Prix - Practice 3: /workspaces/2019/Bahrain Grand Prix/Practice 3\n",
      "Folder already exists for Bahrain Grand Prix - Qualifying: /workspaces/2019/Bahrain Grand Prix/Qualifying\n",
      "Folder already exists for Bahrain Grand Prix - Race: /workspaces/2019/Bahrain Grand Prix/Race\n",
      "Folder already exists for Chinese Grand Prix: /workspaces/2019/Chinese Grand Prix\n",
      "Folder already exists for Chinese Grand Prix - Practice 1: /workspaces/2019/Chinese Grand Prix/Practice 1\n",
      "Folder already exists for Chinese Grand Prix - Practice 2: /workspaces/2019/Chinese Grand Prix/Practice 2\n",
      "Folder already exists for Chinese Grand Prix - Practice 3: /workspaces/2019/Chinese Grand Prix/Practice 3\n",
      "Folder already exists for Chinese Grand Prix - Qualifying: /workspaces/2019/Chinese Grand Prix/Qualifying\n",
      "Folder already exists for Chinese Grand Prix - Race: /workspaces/2019/Chinese Grand Prix/Race\n",
      "Folder already exists for Azerbaijan Grand Prix: /workspaces/2019/Azerbaijan Grand Prix\n",
      "Folder already exists for Azerbaijan Grand Prix - Practice 1: /workspaces/2019/Azerbaijan Grand Prix/Practice 1\n",
      "Folder already exists for Azerbaijan Grand Prix - Practice 2: /workspaces/2019/Azerbaijan Grand Prix/Practice 2\n",
      "Folder already exists for Azerbaijan Grand Prix - Practice 3: /workspaces/2019/Azerbaijan Grand Prix/Practice 3\n",
      "Folder already exists for Azerbaijan Grand Prix - Qualifying: /workspaces/2019/Azerbaijan Grand Prix/Qualifying\n",
      "Folder already exists for Azerbaijan Grand Prix - Race: /workspaces/2019/Azerbaijan Grand Prix/Race\n",
      "Folder already exists for Spanish Grand Prix: /workspaces/2019/Spanish Grand Prix\n",
      "Folder already exists for Spanish Grand Prix - Practice 1: /workspaces/2019/Spanish Grand Prix/Practice 1\n",
      "Folder already exists for Spanish Grand Prix - Practice 2: /workspaces/2019/Spanish Grand Prix/Practice 2\n",
      "Folder already exists for Spanish Grand Prix - Practice 3: /workspaces/2019/Spanish Grand Prix/Practice 3\n",
      "Folder already exists for Spanish Grand Prix - Qualifying: /workspaces/2019/Spanish Grand Prix/Qualifying\n",
      "Folder already exists for Spanish Grand Prix - Race: /workspaces/2019/Spanish Grand Prix/Race\n",
      "Folder already exists for Monaco Grand Prix: /workspaces/2019/Monaco Grand Prix\n",
      "Folder already exists for Monaco Grand Prix - Practice 1: /workspaces/2019/Monaco Grand Prix/Practice 1\n",
      "Folder already exists for Monaco Grand Prix - Practice 2: /workspaces/2019/Monaco Grand Prix/Practice 2\n",
      "Folder already exists for Monaco Grand Prix - Practice 3: /workspaces/2019/Monaco Grand Prix/Practice 3\n",
      "Folder already exists for Monaco Grand Prix - Qualifying: /workspaces/2019/Monaco Grand Prix/Qualifying\n",
      "Folder already exists for Monaco Grand Prix - Race: /workspaces/2019/Monaco Grand Prix/Race\n",
      "Folder already exists for Canadian Grand Prix: /workspaces/2019/Canadian Grand Prix\n",
      "Folder already exists for Canadian Grand Prix - Practice 1: /workspaces/2019/Canadian Grand Prix/Practice 1\n",
      "Folder already exists for Canadian Grand Prix - Practice 2: /workspaces/2019/Canadian Grand Prix/Practice 2\n",
      "Folder already exists for Canadian Grand Prix - Practice 3: /workspaces/2019/Canadian Grand Prix/Practice 3\n",
      "Folder already exists for Canadian Grand Prix - Qualifying: /workspaces/2019/Canadian Grand Prix/Qualifying\n",
      "Folder already exists for Canadian Grand Prix - Race: /workspaces/2019/Canadian Grand Prix/Race\n",
      "Folder already exists for French Grand Prix: /workspaces/2019/French Grand Prix\n",
      "Folder already exists for French Grand Prix - Practice 1: /workspaces/2019/French Grand Prix/Practice 1\n",
      "Folder already exists for French Grand Prix - Practice 2: /workspaces/2019/French Grand Prix/Practice 2\n",
      "Folder already exists for French Grand Prix - Practice 3: /workspaces/2019/French Grand Prix/Practice 3\n",
      "Folder already exists for French Grand Prix - Qualifying: /workspaces/2019/French Grand Prix/Qualifying\n",
      "Folder already exists for French Grand Prix - Race: /workspaces/2019/French Grand Prix/Race\n",
      "Folder already exists for Austrian Grand Prix: /workspaces/2019/Austrian Grand Prix\n",
      "Folder already exists for Austrian Grand Prix - Practice 1: /workspaces/2019/Austrian Grand Prix/Practice 1\n",
      "Folder already exists for Austrian Grand Prix - Practice 2: /workspaces/2019/Austrian Grand Prix/Practice 2\n",
      "Folder already exists for Austrian Grand Prix - Practice 3: /workspaces/2019/Austrian Grand Prix/Practice 3\n",
      "Folder already exists for Austrian Grand Prix - Qualifying: /workspaces/2019/Austrian Grand Prix/Qualifying\n",
      "Folder already exists for Austrian Grand Prix - Race: /workspaces/2019/Austrian Grand Prix/Race\n",
      "Folder already exists for British Grand Prix: /workspaces/2019/British Grand Prix\n",
      "Folder already exists for British Grand Prix - Practice 1: /workspaces/2019/British Grand Prix/Practice 1\n",
      "Folder already exists for British Grand Prix - Practice 2: /workspaces/2019/British Grand Prix/Practice 2\n",
      "Folder already exists for British Grand Prix - Practice 3: /workspaces/2019/British Grand Prix/Practice 3\n",
      "Folder already exists for British Grand Prix - Qualifying: /workspaces/2019/British Grand Prix/Qualifying\n",
      "Folder already exists for British Grand Prix - Race: /workspaces/2019/British Grand Prix/Race\n",
      "Folder already exists for German Grand Prix: /workspaces/2019/German Grand Prix\n",
      "Folder already exists for German Grand Prix - Practice 1: /workspaces/2019/German Grand Prix/Practice 1\n",
      "Folder already exists for German Grand Prix - Practice 2: /workspaces/2019/German Grand Prix/Practice 2\n",
      "Folder already exists for German Grand Prix - Practice 3: /workspaces/2019/German Grand Prix/Practice 3\n",
      "Folder already exists for German Grand Prix - Qualifying: /workspaces/2019/German Grand Prix/Qualifying\n",
      "Folder already exists for German Grand Prix - Race: /workspaces/2019/German Grand Prix/Race\n",
      "Folder already exists for Hungarian Grand Prix: /workspaces/2019/Hungarian Grand Prix\n",
      "Folder already exists for Hungarian Grand Prix - Practice 1: /workspaces/2019/Hungarian Grand Prix/Practice 1\n",
      "Folder already exists for Hungarian Grand Prix - Practice 2: /workspaces/2019/Hungarian Grand Prix/Practice 2\n",
      "Folder already exists for Hungarian Grand Prix - Practice 3: /workspaces/2019/Hungarian Grand Prix/Practice 3\n",
      "Folder already exists for Hungarian Grand Prix - Qualifying: /workspaces/2019/Hungarian Grand Prix/Qualifying\n",
      "Folder already exists for Hungarian Grand Prix - Race: /workspaces/2019/Hungarian Grand Prix/Race\n",
      "Folder already exists for Belgian Grand Prix: /workspaces/2019/Belgian Grand Prix\n",
      "Folder already exists for Belgian Grand Prix - Practice 1: /workspaces/2019/Belgian Grand Prix/Practice 1\n",
      "Folder already exists for Belgian Grand Prix - Practice 2: /workspaces/2019/Belgian Grand Prix/Practice 2\n",
      "Folder already exists for Belgian Grand Prix - Practice 3: /workspaces/2019/Belgian Grand Prix/Practice 3\n",
      "Folder already exists for Belgian Grand Prix - Qualifying: /workspaces/2019/Belgian Grand Prix/Qualifying\n",
      "Folder already exists for Belgian Grand Prix - Race: /workspaces/2019/Belgian Grand Prix/Race\n",
      "Folder already exists for Italian Grand Prix: /workspaces/2019/Italian Grand Prix\n",
      "Folder already exists for Italian Grand Prix - Practice 1: /workspaces/2019/Italian Grand Prix/Practice 1\n",
      "Folder already exists for Italian Grand Prix - Practice 2: /workspaces/2019/Italian Grand Prix/Practice 2\n",
      "Folder already exists for Italian Grand Prix - Practice 3: /workspaces/2019/Italian Grand Prix/Practice 3\n",
      "Folder already exists for Italian Grand Prix - Qualifying: /workspaces/2019/Italian Grand Prix/Qualifying\n",
      "Folder already exists for Italian Grand Prix - Race: /workspaces/2019/Italian Grand Prix/Race\n",
      "Folder already exists for Singapore Grand Prix: /workspaces/2019/Singapore Grand Prix\n",
      "Folder already exists for Singapore Grand Prix - Practice 1: /workspaces/2019/Singapore Grand Prix/Practice 1\n",
      "Folder already exists for Singapore Grand Prix - Practice 2: /workspaces/2019/Singapore Grand Prix/Practice 2\n",
      "Folder already exists for Singapore Grand Prix - Practice 3: /workspaces/2019/Singapore Grand Prix/Practice 3\n",
      "Folder already exists for Singapore Grand Prix - Qualifying: /workspaces/2019/Singapore Grand Prix/Qualifying\n",
      "Folder already exists for Singapore Grand Prix - Race: /workspaces/2019/Singapore Grand Prix/Race\n",
      "Folder already exists for Russian Grand Prix: /workspaces/2019/Russian Grand Prix\n",
      "Folder already exists for Russian Grand Prix - Practice 1: /workspaces/2019/Russian Grand Prix/Practice 1\n",
      "Folder already exists for Russian Grand Prix - Practice 2: /workspaces/2019/Russian Grand Prix/Practice 2\n",
      "Folder already exists for Russian Grand Prix - Practice 3: /workspaces/2019/Russian Grand Prix/Practice 3\n",
      "Folder already exists for Russian Grand Prix - Qualifying: /workspaces/2019/Russian Grand Prix/Qualifying\n",
      "Folder already exists for Russian Grand Prix - Race: /workspaces/2019/Russian Grand Prix/Race\n",
      "Folder already exists for Japanese Grand Prix: /workspaces/2019/Japanese Grand Prix\n",
      "Folder already exists for Japanese Grand Prix - Practice 1: /workspaces/2019/Japanese Grand Prix/Practice 1\n",
      "Folder already exists for Japanese Grand Prix - Practice 2: /workspaces/2019/Japanese Grand Prix/Practice 2\n",
      "Folder already exists for Japanese Grand Prix - Practice 3: /workspaces/2019/Japanese Grand Prix/Practice 3\n",
      "Folder already exists for Japanese Grand Prix - Qualifying: /workspaces/2019/Japanese Grand Prix/Qualifying\n",
      "Folder already exists for Japanese Grand Prix - Race: /workspaces/2019/Japanese Grand Prix/Race\n",
      "Folder already exists for Mexican Grand Prix: /workspaces/2019/Mexican Grand Prix\n",
      "Folder already exists for Mexican Grand Prix - Practice 1: /workspaces/2019/Mexican Grand Prix/Practice 1\n",
      "Folder already exists for Mexican Grand Prix - Practice 2: /workspaces/2019/Mexican Grand Prix/Practice 2\n",
      "Folder already exists for Mexican Grand Prix - Practice 3: /workspaces/2019/Mexican Grand Prix/Practice 3\n",
      "Folder already exists for Mexican Grand Prix - Qualifying: /workspaces/2019/Mexican Grand Prix/Qualifying\n",
      "Folder already exists for Mexican Grand Prix - Race: /workspaces/2019/Mexican Grand Prix/Race\n",
      "Folder already exists for United States Grand Prix: /workspaces/2019/United States Grand Prix\n",
      "Folder already exists for United States Grand Prix - Practice 1: /workspaces/2019/United States Grand Prix/Practice 1\n",
      "Folder already exists for United States Grand Prix - Practice 2: /workspaces/2019/United States Grand Prix/Practice 2\n",
      "Folder already exists for United States Grand Prix - Practice 3: /workspaces/2019/United States Grand Prix/Practice 3\n",
      "Folder already exists for United States Grand Prix - Qualifying: /workspaces/2019/United States Grand Prix/Qualifying\n",
      "Folder already exists for United States Grand Prix - Race: /workspaces/2019/United States Grand Prix/Race\n",
      "Folder already exists for Brazilian Grand Prix: /workspaces/2019/Brazilian Grand Prix\n",
      "Folder already exists for Brazilian Grand Prix - Practice 1: /workspaces/2019/Brazilian Grand Prix/Practice 1\n",
      "Folder already exists for Brazilian Grand Prix - Practice 2: /workspaces/2019/Brazilian Grand Prix/Practice 2\n",
      "Folder already exists for Brazilian Grand Prix - Practice 3: /workspaces/2019/Brazilian Grand Prix/Practice 3\n",
      "Folder already exists for Brazilian Grand Prix - Qualifying: /workspaces/2019/Brazilian Grand Prix/Qualifying\n",
      "Folder already exists for Brazilian Grand Prix - Race: /workspaces/2019/Brazilian Grand Prix/Race\n",
      "Folder already exists for Abu Dhabi Grand Prix: /workspaces/2019/Abu Dhabi Grand Prix\n",
      "Folder already exists for Abu Dhabi Grand Prix - Practice 1: /workspaces/2019/Abu Dhabi Grand Prix/Practice 1\n",
      "Folder already exists for Abu Dhabi Grand Prix - Practice 2: /workspaces/2019/Abu Dhabi Grand Prix/Practice 2\n",
      "Folder already exists for Abu Dhabi Grand Prix - Practice 3: /workspaces/2019/Abu Dhabi Grand Prix/Practice 3\n",
      "Folder already exists for Abu Dhabi Grand Prix - Qualifying: /workspaces/2019/Abu Dhabi Grand Prix/Qualifying\n",
      "Folder already exists for Abu Dhabi Grand Prix - Race: /workspaces/2019/Abu Dhabi Grand Prix/Race\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Your list of events\n",
    "events_list = events\n",
    "\n",
    "# Loop through each event\n",
    "for event in events_list:\n",
    "    event_directory = os.path.join(os.getcwd(), event)\n",
    "\n",
    "    # Check if the event folder already exists before creating it\n",
    "    if not os.path.exists(event_directory):\n",
    "        os.makedirs(event_directory)\n",
    "        print(f\"Folder created for {event}: {event_directory}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists for {event}: {event_directory}\")\n",
    "\n",
    "    # Get sessions for the current event\n",
    "    sessions = sessions_available(YEAR, event)\n",
    "\n",
    "    # Loop through each session and create a folder within the event folder\n",
    "    for session in sessions:\n",
    "        session_directory = os.path.join(event_directory, session)\n",
    "\n",
    "        # Check if the session folder already exists before creating it\n",
    "        if not os.path.exists(session_directory):\n",
    "            os.makedirs(session_directory)\n",
    "            print(f\"Folder created for {event} - {session}: {session_directory}\")\n",
    "        else:\n",
    "            print(f\"Folder already exists for {event} - {session}: {session_directory}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Japanese Grand Prix - Practice 1 [v3.1.6]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "core        WARNING \tNo lap data for driver 10\n",
      "core        WARNING \tFailed to perform lap accuracy check - all laps marked as inaccurate (driver 10)\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tFinished loading data for 21 drivers: ['10', '11', '16', '18', '20', '23', '26', '27', '3', '33', '38', '4', '44', '5', '55', '63', '7', '77', '8', '88', '99']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Practice 2 [v3.1.6]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n",
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['10', '11', '16', '18', '20', '23', '26', '27', '3', '33', '4', '44', '5', '55', '63', '7', '77', '8', '88', '99']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Qualifying [v3.1.6]\n",
      "req            INFO \tNo cached data found for session_info. Loading data...\n",
      "_api           INFO \tFetching session info data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for driver_info. Loading data...\n",
      "_api           INFO \tFetching driver list...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for session_status_data. Loading data...\n",
      "_api           INFO \tFetching session status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for track_status_data. Loading data...\n",
      "_api           INFO \tFetching track status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for _extended_timing_data. Loading data...\n",
      "_api           INFO \tFetching timing data...\n",
      "_api           INFO \tParsing timing data...\n",
      "_api        WARNING \tDriver 44: Ignoring late data for a previously processed lap.The data may contain errors (previous: 12; current 13)\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for timing_app_data. Loading data...\n",
      "_api           INFO \tFetching timing app data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tNo cached data found for car_data. Loading data...\n",
      "_api           INFO \tFetching car data...\n",
      "_api           INFO \tParsing car data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for position_data. Loading data...\n",
      "_api           INFO \tFetching position data...\n",
      "_api           INFO \tParsing position data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tFinished loading data for 20 drivers: ['5', '16', '77', '44', '33', '23', '55', '4', '10', '8', '99', '18', '7', '26', '27', '3', '11', '63', '20', '88']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v3.1.6]\n",
      "req            INFO \tNo cached data found for session_info. Loading data...\n",
      "_api           INFO \tFetching session info data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for driver_info. Loading data...\n",
      "_api           INFO \tFetching driver list...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for session_status_data. Loading data...\n",
      "_api           INFO \tFetching session status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for lap_count. Loading data...\n",
      "_api           INFO \tFetching lap count data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for track_status_data. Loading data...\n",
      "_api           INFO \tFetching track status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for _extended_timing_data. Loading data...\n",
      "_api           INFO \tFetching timing data...\n",
      "_api           INFO \tParsing timing data...\n",
      "_api        WARNING \tDriver  5: Ignoring late data for a previously processed lap.The data may contain errors (previous: 52; current 53)\n",
      "_api        WARNING \tDriver 16: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 77: Ignoring late data for a previously processed lap.The data may contain errors (previous: 52; current 53)\n",
      "_api        WARNING \tDriver 44: Ignoring late data for a previously processed lap.The data may contain errors (previous: 52; current 53)\n",
      "_api        WARNING \tDriver 23: Ignoring late data for a previously processed lap.The data may contain errors (previous: 52; current 53)\n",
      "_api        WARNING \tDriver 55: Ignoring late data for a previously processed lap.The data may contain errors (previous: 52; current 53)\n",
      "_api        WARNING \tDriver  4: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 10: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver  8: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 99: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 18: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver  7: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 26: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 27: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver  3: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 63: Ignoring late data for a previously processed lap.The data may contain errors (previous: 50; current 51)\n",
      "_api        WARNING \tDriver 20: Ignoring late data for a previously processed lap.The data may contain errors (previous: 51; current 52)\n",
      "_api        WARNING \tDriver 88: Ignoring late data for a previously processed lap.The data may contain errors (previous: 50; current 51)\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for timing_app_data. Loading data...\n",
      "_api           INFO \tFetching timing app data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tNo cached data found for car_data. Loading data...\n",
      "_api           INFO \tFetching car data...\n",
      "_api           INFO \tParsing car data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for position_data. Loading data...\n",
      "_api           INFO \tFetching position data...\n",
      "_api           INFO \tParsing position data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '5', '44', '23', '55', '16', '10', '11', '18', '26', '4', '7', '8', '99', '20', '63', '88', '33', '3', '27']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to Japanese Grand Prix/Race/drivers.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Your list of events\n",
    "events_list = events\n",
    "\n",
    "# Loop through each event\n",
    "for event in events_list:\n",
    "    # Get sessions for the current event\n",
    "\n",
    "    if event == \"Japanese Grand Prix\":\n",
    "\n",
    "        sessions = ['Practice 1', 'Practice 2', 'Qualifying', 'Race']\n",
    "        # fp3 and saturday wipedout due to typoons, quali took place on sunday 4hrs before race\n",
    "    else:\n",
    "         sessions = sessions_available(YEAR, event)\n",
    "\n",
    "    # Loop through each session and create a folder within the event folder\n",
    "    for session in sessions:\n",
    "        drivers = session_drivers(YEAR, event, session)\n",
    "\n",
    "        import json\n",
    "\n",
    "        # Specify the file path where you want to save the JSON data\n",
    "        file_path = f\"{event}/{session}/drivers.json\"\n",
    "\n",
    "        # Save the dictionary to a JSON file\n",
    "        with open(file_path, \"w\") as json_file:\n",
    "            json.dump(drivers, json_file)\n",
    "\n",
    "    print(f\"Dictionary saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_drivers_list(year: int, event: str | int, session: str) -> any:\n",
    "    # get drivers available for a given year, event and session\n",
    "    import fastf1\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=True, weather=False, messages=False)\n",
    "\n",
    "    laps = f1session.laps\n",
    "\n",
    "\n",
    "    unique_drivers = laps[\"Driver\"].unique()\n",
    "\n",
    "\n",
    "    return  list(unique_drivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v3.1.6]\n",
      "req            INFO \tNo cached data found for session_info. Loading data...\n",
      "_api           INFO \tFetching session info data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for driver_info. Loading data...\n",
      "_api           INFO \tFetching driver list...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for session_status_data. Loading data...\n",
      "_api           INFO \tFetching session status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for lap_count. Loading data...\n",
      "_api           INFO \tFetching lap count data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for track_status_data. Loading data...\n",
      "_api           INFO \tFetching track status data...\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for _extended_timing_data. Loading data...\n",
      "_api           INFO \tFetching timing data...\n",
      "_api           INFO \tParsing timing data...\n",
      "_api        WARNING \tSkipping lap alignment (no suitable lap)!\n",
      "req            INFO \tData has been written to cache!\n",
      "req            INFO \tNo cached data found for timing_app_data. Loading data...\n",
      "_api           INFO \tFetching timing app data...\n",
      "req            INFO \tData has been written to cache!\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tNo cached data found for car_data. Loading data...\n",
      "_api           INFO \tFetching car data...\n",
      "core        WARNING \tCar telemetry data is unavailable!\n",
      "req            INFO \tNo cached data found for position_data. Loading data...\n",
      "_api           INFO \tFetching position data...\n",
      "core        WARNING \tCar position data is unavailable!\n",
      "core        WARNING \tFailed to determine `Session.t0_date`!\n",
      "logger      WARNING \tFailed to load telemetry data!\n",
      "core           INFO \tFinished loading data for 20 drivers: ['5', '77', '44', '10', '20', '27', '14', '2', '9', '31', '55', '16', '8', '18', '35', '11', '28', '7', '33', '3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GAS',\n",
       " 'PER',\n",
       " 'ALO',\n",
       " 'LEC',\n",
       " 'STR',\n",
       " 'VAN',\n",
       " 'MAG',\n",
       " 'HUL',\n",
       " 'HAR',\n",
       " 'RIC',\n",
       " 'OCO',\n",
       " 'VER',\n",
       " 'SIR',\n",
       " 'HAM',\n",
       " 'VET',\n",
       " 'SAI',\n",
       " 'RAI',\n",
       " 'BOT',\n",
       " 'GRO',\n",
       " 'ERI']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_drivers_list(2018,\"Bahrain Grand Prix\", \"Race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laps_data(year: int, event: str | int, session: str, driver: str) -> any:\n",
    "    # get drivers available for a given year, event, and session\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "\n",
    "    # add team_colors dict to laps on Team column\n",
    "\n",
    "    # for each driver in drivers, get the Team column from laps and get the color from team_colors dict\n",
    "    drivers_data = []\n",
    "\n",
    "    driver_laps = laps.pick_driver(driver)\n",
    "    driver_laps[\"LapTime\"] = driver_laps[\"LapTime\"].dt.total_seconds()\n",
    "    # remove rows where LapTime is null\n",
    "    driver_laps = driver_laps[driver_laps.LapTime.notnull()]\n",
    "\n",
    "    drivers_data = {\n",
    "        \"time\": driver_laps[\"LapTime\"].tolist(),\n",
    "        \"lap\": driver_laps[\"LapNumber\"].tolist(),\n",
    "        \"compound\": driver_laps[\"Compound\"].tolist(),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    return drivers_data\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# result = laps_data(2018, \"Bahrain\", \"R\", \"GAS\")\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reversing a pyton list\n",
    "# events.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Australian Grand Prix - Practice 1 [v3.1.6]\n",
      "req            INFO \tUsing cached data for session_info\n",
      "req            INFO \tUsing cached data for driver_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req            INFO \tUsing cached data for session_status_data\n",
      "req            INFO \tUsing cached data for track_status_data\n",
      "req            INFO \tUsing cached data for _extended_timing_data\n",
      "req            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "req            INFO \tUsing cached data for car_data\n",
      "req            INFO \tUsing cached data for position_data\n",
      "core           INFO \tFinished loading data for 20 drivers: ['10', '11', '16', '18', '20', '23', '26', '27', '3', '33', '4', '44', '5', '55', '63', '7', '77', '8', '88', '99']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Your list of events\n",
    "events_list = events\n",
    "\n",
    "# Loop through each event\n",
    "for event in events_list:\n",
    "\n",
    "    if event == \"Japanese Grand Prix\":\n",
    "\n",
    "        sessions = ['Practice 1', 'Practice 2', 'Qualifying', 'Race']\n",
    "    else:\n",
    "         sessions = sessions_available(YEAR, event)\n",
    "\n",
    "    # Loop through each session and create a folder within the event folder\n",
    "    for session in sessions:\n",
    "        drivers = session_drivers_list(YEAR, event, session)\n",
    "\n",
    "        for driver in drivers:\n",
    "            # Create a folder for the driver if it doesn't exist\n",
    "            driver_folder = f\"{event}/{session}/{driver}\"\n",
    "            if not os.path.exists(driver_folder):\n",
    "                os.makedirs(driver_folder)\n",
    "\n",
    "            laptimes = laps_data(YEAR, event, session, driver)\n",
    "\n",
    "            # Specify the file path where you want to save the JSON data\n",
    "            file_path = f\"{driver_folder}/laptimes.json\"\n",
    "\n",
    "            # Save the dictionary to a JSON file\n",
    "            with open(file_path, \"w\") as json_file:\n",
    "                json.dump(laptimes, json_file)\n",
    "\n",
    "            # print(f\"Dictionary saved to {file_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import datetime\n",
    "import functools\n",
    "import math\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "import fastf1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import streamlit as st\n",
    "from fastapi import Depends, FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import FileResponse, HTMLResponse\n",
    "from fastf1.ergast import Ergast\n",
    "from pydantic import BaseModel, Field\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "from . import accelerations, database, models, utils\n",
    "\n",
    "# import accelerations\n",
    "# import database\n",
    "# import models\n",
    "# import utils\n",
    "FASTF1_CACHE_DIR = os.environ[\"FASTF1_CACHE_DIR\"]\n",
    "\n",
    "fastf1.Cache.enable_cache(FASTF1_CACHE_DIR)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "\n",
    "database.Base.metadata.create_all(bind=database.engine)\n",
    "\n",
    "\n",
    "def get_db():\n",
    "    try:\n",
    "        db = database.SessionLocal()\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "\n",
    "class RacePace(BaseModel):\n",
    "    year: int\n",
    "    event: str\n",
    "    session: str\n",
    "    Driver: str\n",
    "    LapTime: float\n",
    "    Diff: float\n",
    "    Team: str\n",
    "    fill: str\n",
    "\n",
    "\n",
    "# @functools.cache\n",
    "@app.get(\"/racepace/{year}/{event}/{session}\", response_model=None)\n",
    "async def average_race_pace(\n",
    "    year: int, event: str | int, session: str, db: Session = Depends(get_db)\n",
    ") -> any:\n",
    "    race_pace_data = (\n",
    "        db.query(models.RacePace)\n",
    "        .filter_by(year=year, event=event, session=session)\n",
    "        .all()\n",
    "    )\n",
    "\n",
    "    if race_pace_data:\n",
    "        print(\"Fetching from Database\")\n",
    "\n",
    "    if not race_pace_data:\n",
    "        print(\"Writing to Database\")\n",
    "        f1session = fastf1.get_session(\n",
    "            year,\n",
    "            event,\n",
    "            session,\n",
    "            # backend=\"fastf1\",\n",
    "            # force_ergast=False,\n",
    "        )\n",
    "        f1session.load(telemetry=False, weather=False, messages=False)\n",
    "        laps = f1session.laps\n",
    "\n",
    "        laps = laps.loc[laps.LapNumber > 1]\n",
    "        laps = laps.pick_track_status(\n",
    "            \"1\",\n",
    "        )\n",
    "        laps[\"LapTime\"] = laps.Sector1Time + laps.Sector2Time + laps.Sector3Time\n",
    "\n",
    "        # convert LapTime to seconds\n",
    "        laps[\"LapTime\"] = laps[\"LapTime\"].apply(lambda x: x.total_seconds())\n",
    "\n",
    "        laps = laps.loc[laps.LapTime < laps.LapTime.min() * 1.07]\n",
    "\n",
    "        df = (\n",
    "            laps[[\"LapTime\", \"Driver\"]].groupby(\"Driver\").mean().reset_index(drop=False)\n",
    "        )\n",
    "        df = df.sort_values(by=\"LapTime\").reset_index(drop=True)\n",
    "        df[\"LapTime\"] = df[\"LapTime\"].round(3)\n",
    "        df[\"Diff\"] = (df[\"LapTime\"] - df[\"LapTime\"].min()).round(3)\n",
    "        teams = laps[[\"Driver\", \"Team\"]].drop_duplicates().reset_index(drop=True)\n",
    "        # join teams and df\n",
    "        df = df.merge(teams, on=\"Driver\", how=\"left\")\n",
    "\n",
    "        car_colors = utils.team_colors(year)\n",
    "\n",
    "        df[\"fill\"] = df[\"Team\"].map(car_colors)\n",
    "\n",
    "        df_json = df.to_dict(\"records\")\n",
    "\n",
    "        # save the data to the database\n",
    "        for record in df.to_dict(\"records\"):\n",
    "            race_pace = models.RacePace(**record)\n",
    "            db.add(race_pace)\n",
    "\n",
    "        db.commit()\n",
    "\n",
    "        return {\"racePace\": df_json}\n",
    "\n",
    "    return {\"racePace\": [dict(race_pace) for race_pace in race_pace_data]}\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/topspeed/{year}/{event}/{session}\", response_model=None)\n",
    "async def top_speed(year: int, event: str | int, session: str) -> any:\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "    team_colors = utils.team_colors(year)\n",
    "\n",
    "    fastest_speedtrap = (\n",
    "        laps[[\"SpeedI1\", \"SpeedI2\", \"SpeedST\", \"SpeedFL\"]]\n",
    "        .idxmax(axis=1)\n",
    "        .value_counts()\n",
    "        .index[0]\n",
    "    )\n",
    "\n",
    "    speed_df = (\n",
    "        laps[[fastest_speedtrap, \"Driver\", \"Compound\", \"Team\"]]\n",
    "        .groupby(\"Driver\")\n",
    "        .max()\n",
    "        .sort_values(fastest_speedtrap, ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "    # add team colors to dataframe\n",
    "    speed_df[\"fill\"] = speed_df[\"Team\"].apply(lambda x: team_colors[x])\n",
    "\n",
    "    # rename fastest speedtrap column to TopSpeed\n",
    "    speed_df.rename(columns={fastest_speedtrap: \"TopSpeed\"}, inplace=True)\n",
    "\n",
    "    # remove nan values in any column\n",
    "    speed_df = speed_df.dropna()\n",
    "\n",
    "    # Convert to int\n",
    "    speed_df[\"TopSpeed\"] = speed_df[\"TopSpeed\"].astype(int)\n",
    "\n",
    "    speed_dict = speed_df.to_dict(orient=\"records\")\n",
    "\n",
    "    return {\"topSpeed\": speed_dict}\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/overtakes/{year}/{event}\", response_model=None)\n",
    "def get_overtakes(year: int, event: str) -> any:\n",
    "    def get_overtakes_df(year, event):\n",
    "        if year == 2023:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1M4aepPJaIfdqE9oU3L-2CQqKIyubLXG4Q4cqWnyqxp4/export?format=csv\"\n",
    "        if year == 2022:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1cuS3B6hk4iQmMaRQoMTcogIInJpavnV7rKuEsiJnEbU/export?format=csv\"\n",
    "        if year == 2021:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1ANQnPVkefRmvzrmGvEqXoqQ4dBfgcI_R9FPg-0BcM34/export?format=csv\"\n",
    "        if year == 2020:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1eG9WTkXKzFT4NMh-WqHOMs5G0UuPGnb6wP4CnFD8uzY/export?format=csv\"\n",
    "        if year == 2019:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/10nHg7BIs5ySh_dE9uuIz2lq-gRWcg02tIMr0EPgPvJs/export?format=csv\"\n",
    "        if year == 2018:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1MyAwQdczccdca_FAIiZKkqZNauNh3ts99JZ278S2OKc/export?format=csv\"\n",
    "\n",
    "        response = requests.get(url, timeout=10)\n",
    "        df = pd.read_csv(BytesIO(response.content))\n",
    "        df = df[[\"Driver\", event]]\n",
    "        # replace NaNs with 0s\n",
    "        df = df.fillna(0)\n",
    "        # convert numbers to ints\n",
    "        df[event] = df[event].astype(int)\n",
    "        # replace event with \"overtakes\"\n",
    "        df = df.rename(columns={event: \"overtakes\"})\n",
    "        return df\n",
    "\n",
    "    def get_overtaken_df(year, event):\n",
    "        if year == 2023:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1wszzx694Ot-mvA5YrFCpy3or37xMgnC0XpE8uNnJLWk/export?format=csv\"\n",
    "        if year == 2022:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/19_XFDD3BZDIQVkNE4bG6dwuKvMaO4g5HNaUARGaJwhE/export?format=csv\"\n",
    "        if year == 2021:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1dQBHnd3AXEPNH5I75cjbzAAzi9ipqGk3v9eZT9eYKS4/export?format=csv\"\n",
    "        if year == 2020:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1snyntPMxYH4_KHSRI96AwBoJQrPbX6OanJAcqbYyW-Y/export?format=csv\"\n",
    "        if year == 2019:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/11FfFkXErJg7F22iVwJo9XfLFAWucMBVlzL1qUGWxM3s/export?format=csv\"\n",
    "        if year == 2018:\n",
    "            url = \"https://docs.google.com/spreadsheets/d/1XJXAEyRpRS_UwLHzEtN2PdIaFJYGWSN6ypYN8Ecwp9A/export?format=csv\"\n",
    "\n",
    "        response = requests.get(url, timeout=10)\n",
    "        df = pd.read_csv(BytesIO(response.content))\n",
    "        df = df[[\"Driver\", event]]\n",
    "        # replace NaNs with 0s\n",
    "        df = df.fillna(0)\n",
    "        # convert numbers to ints\n",
    "        df[event] = df[event].astype(int)\n",
    "        df = df.rename(columns={event: \"overtaken\"})\n",
    "        return df\n",
    "\n",
    "    overtakes = get_overtakes_df(year, event)\n",
    "    overtaken = get_overtaken_df(year, event)\n",
    "    df = overtakes.merge(overtaken, on=\"Driver\")\n",
    "\n",
    "    # remove drivers with 0 overtakes and 0 overtaken\n",
    "    df = df[(df[\"overtakes\"] != 0) | (df[\"overtaken\"] != 0)]\n",
    "\n",
    "    # sort in the decreasing order of overtakes\n",
    "    df = df.sort_values(\n",
    "        by=[\"overtakes\", \"overtaken\"], ascending=[False, True]\n",
    "    ).reset_index(drop=True)\n",
    "    # convert to dictionary\n",
    "    df_dict = df.to_dict(orient=\"records\")\n",
    "\n",
    "    return {\"overtakes\": df_dict}\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/fastest/{year}/{event}/{session}\", response_model=None)\n",
    "async def fastest_lap(year: int, event: str | int, session: str) -> any:\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "\n",
    "    drivers = pd.unique(laps[\"Driver\"])\n",
    "\n",
    "    list_fastest_laps = list()\n",
    "\n",
    "    for drv in drivers:\n",
    "        drvs_fastest_lap = laps.pick_driver(drv).pick_fastest()\n",
    "        list_fastest_laps.append(drvs_fastest_lap)\n",
    "\n",
    "    df = (\n",
    "        fastf1.core.Laps(list_fastest_laps)\n",
    "        .sort_values(by=\"LapTime\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    pole_lap = df.pick_fastest()\n",
    "    df[\"Diff\"] = df[\"LapTime\"] - pole_lap[\"LapTime\"]\n",
    "\n",
    "    car_colors = utils.team_colors(year)\n",
    "\n",
    "    df[\"fill\"] = df[\"Team\"].map(car_colors)\n",
    "\n",
    "    # convert timedelta to float and round to 3 decimal places\n",
    "    df[\"Diff\"] = df[\"Diff\"].dt.total_seconds().round(3)\n",
    "    df = df[[\"Driver\", \"LapTime\", \"Diff\", \"Team\", \"fill\"]]\n",
    "\n",
    "    # remove nan values in any column\n",
    "    df = df.dropna()\n",
    "\n",
    "    df_json = df.to_dict(\"records\")\n",
    "\n",
    "    return {\"fastest\": df_json}\n",
    "\n",
    "\n",
    "# @st.cache_data\n",
    "\n",
    "\n",
    "@app.get(\"/wdc\", response_model=None)\n",
    "async def driver_standings() -> any:\n",
    "    YEAR = 2023  # datetime.datetime.now().year\n",
    "    df = pd.DataFrame(\n",
    "        pd.read_html(f\"https://www.formula1.com/en/results.html/{YEAR}/drivers.html\")[0]\n",
    "    )\n",
    "    df = df[[\"Driver\", \"PTS\", \"Car\"]]\n",
    "    # reverse the order\n",
    "    df = df.sort_values(by=\"PTS\", ascending=True)\n",
    "\n",
    "    # in Driver column only keep the last 3 characters\n",
    "    df[\"Driver\"] = df[\"Driver\"].str[:-5]\n",
    "\n",
    "    # add colors to the dataframe\n",
    "    car_colors = utils.team_colors(YEAR)\n",
    "    df[\"fill\"] = df[\"Car\"].map(car_colors)\n",
    "\n",
    "    # remove rows where points is 0\n",
    "    df = df[df[\"PTS\"] != 0]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df.rename(columns={\"PTS\": \"Points\"}, inplace=True)\n",
    "\n",
    "    return {\"WDC\": df.to_dict(\"records\")}\n",
    "\n",
    "\n",
    "# @st.cache_data\n",
    "\n",
    "\n",
    "@app.get(\"/\", response_model=None)\n",
    "async def root():\n",
    "    return HTMLResponse(\n",
    "        content=\"\"\"<iframe src=\"https://tracinginsights-f1-analysis.hf.space\" frameborder=\"0\" style=\"width:100%; height:100%;\" scrolling=\"yes\" allowfullscreen:\"yes\"></iframe>\"\"\",\n",
    "        status_code=200,\n",
    "    )\n",
    "\n",
    "\n",
    "# @st.cache_data\n",
    "\n",
    "\n",
    "@app.get(\"/years\", response_model=None)\n",
    "async def years_available() -> any:\n",
    "    # make a list from 2018 to current year\n",
    "    current_year = datetime.datetime.now().year\n",
    "    years = list(range(2018, current_year + 1))\n",
    "    # reverse the list to get the latest year first\n",
    "    years.reverse()\n",
    "    years = [{\"label\": str(year), \"value\": year} for year in years]\n",
    "    return {\"years\": years}\n",
    "\n",
    "\n",
    "# format for events {\"events\":[{\"label\":\"Saudi Arabian Grand Prix\",\"value\":2},{\"label\":\"Bahrain Grand Prix\",\"value\":1},{\"label\":\"Pre-Season Testing\",\"value\":\"t1\"}]}\n",
    "\n",
    "# @st.cache_data\n",
    "\n",
    "\n",
    "@app.get(\"/{year}\", response_model=None)\n",
    "async def events_available(year: int) -> any:\n",
    "    # get events available for a given year\n",
    "    data = utils.LatestData(year)\n",
    "    events = data.get_events()\n",
    "    events = [{\"label\": event, \"value\": event} for i, event in enumerate(events)]\n",
    "    events.reverse()\n",
    "\n",
    "    return {\"events\": events}\n",
    "\n",
    "\n",
    "# format for sessions {\"sessions\":[{\"label\":\"FP1\",\"value\":\"FP1\"},{\"label\":\"FP2\",\"value\":\"FP2\"},{\"label\":\"FP3\",\"value\":\"FP3\"},{\"label\":\"Qualifying\",\"value\":\"Q\"},{\"label\":\"Race\",\"value\":\"R\"}]}\n",
    "\n",
    "\n",
    "# @st.cache_data\n",
    "@functools.cache\n",
    "@app.get(\"/{year}/{event}\", response_model=None)\n",
    "async def sessions_available(year: int, event: str | int) -> any:\n",
    "    # get sessions available for a given year and event\n",
    "    data = utils.LatestData(year)\n",
    "    sessions = data.get_sessions(event)\n",
    "    sessions = [{\"label\": session, \"value\": session} for session in sessions]\n",
    "\n",
    "    return {\"sessions\": sessions}\n",
    "\n",
    "\n",
    "# format for drivers {\"drivers\":[{\"color\":\"#fff500\",\"label\":\"RIC\",\"value\":\"RIC\"},{\"color\":\"#ff8700\",\"label\":\"NOR\",\"value\":\"NOR\"},{\"color\":\"#c00000\",\"label\":\"VET\",\"value\":\"VET\"},{\"color\":\"#0082fa\",\"label\":\"LAT\",\"value\":\"LAT\"},{\"color\":\"#787878\",\"label\":\"GRO\",\"value\":\"GRO\"},{\"color\":\"#ffffff\",\"label\":\"GAS\",\"value\":\"GAS\"},{\"color\":\"#f596c8\",\"label\":\"STR\",\"value\":\"STR\"},{\"color\":\"#787878\",\"label\":\"MAG\",\"value\":\"MAG\"},{\"color\":\"#0600ef\",\"label\":\"ALB\",\"value\":\"ALB\"},{\"color\":\"#ffffff\",\"label\":\"KVY\",\"value\":\"KVY\"},{\"color\":\"#fff500\",\"label\":\"OCO\",\"value\":\"OCO\"},{\"color\":\"#0600ef\",\"label\":\"VER\",\"value\":\"VER\"},{\"color\":\"#00d2be\",\"label\":\"HAM\",\"value\":\"HAM\"},{\"color\":\"#ff8700\",\"label\":\"SAI\",\"value\":\"SAI\"},{\"color\":\"#00d2be\",\"label\":\"BOT\",\"value\":\"BOT\"},{\"color\":\"#960000\",\"label\":\"GIO\",\"value\":\"GIO\"}]}\n",
    "\n",
    "# @st.cache_data\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/strategy/{year}/{event}\", response_model=None)\n",
    "async def get_strategy(year: int, event: str | int) -> any:\n",
    "    f1session = fastf1.get_session(year, event, \"R\")\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "\n",
    "    drivers_list = pd.unique(laps[\"Driver\"])\n",
    "\n",
    "    drivers = pd.DataFrame(drivers_list, columns=[\"Driver\"])\n",
    "    drivers[\"FinishOrder\"] = drivers.index + 1\n",
    "\n",
    "    # Get the LapNumber of the first lap of each stint\n",
    "    first_lap = (\n",
    "        laps[[\"Driver\", \"Stint\", \"Compound\", \"LapNumber\"]]\n",
    "        .groupby([\"Driver\", \"Stint\", \"Compound\"])\n",
    "        .first()\n",
    "        .reset_index()\n",
    "    )\n",
    "    #  Add FinishOrder to first_lap\n",
    "    first_lap = pd.merge(first_lap, drivers, on=\"Driver\")\n",
    "    # change LapNumber to LapStart\n",
    "    first_lap = first_lap.rename(columns={\"LapNumber\": \"LapStart\"})\n",
    "    # reduce the lapstart by 1\n",
    "    first_lap[\"LapStart\"] = first_lap[\"LapStart\"] - 1\n",
    "\n",
    "    # find the last lap of each stint\n",
    "    last_lap = (\n",
    "        laps[[\"Driver\", \"Stint\", \"Compound\", \"LapNumber\"]]\n",
    "        .groupby([\"Driver\", \"Stint\", \"Compound\"])\n",
    "        .last()\n",
    "        .reset_index()\n",
    "    )\n",
    "    #  change LapNumber to LapEnd\n",
    "    last_lap = last_lap.rename(columns={\"LapNumber\": \"LapEnd\"})\n",
    "\n",
    "    # combine first_lap and last_lap\n",
    "    stint_laps = pd.merge(first_lap, last_lap, on=[\"Driver\", \"Stint\", \"Compound\"])\n",
    "    #  to cover for outliers\n",
    "    stint_laps[\"fill\"] = \"white\"\n",
    "\n",
    "    stint_laps[\"fill\"] = stint_laps[\"Compound\"].map(\n",
    "        {\n",
    "            \"SOFT\": \"red\",\n",
    "            \"MEDIUM\": \"yellow\",\n",
    "            \"HARD\": \"white\",\n",
    "            \"INTERMEDIATE\": \"blue\",\n",
    "            \"WET\": \"green\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # sort by FinishOrder\n",
    "    stint_laps = stint_laps.sort_values(by=[\"FinishOrder\"], ascending=[True])\n",
    "\n",
    "    stint_laps_dict = stint_laps.to_dict(\"records\")\n",
    "\n",
    "    return {\"strategy\": stint_laps_dict}\n",
    "\n",
    "# lap position\n",
    "@functools.cache\n",
    "@app.get(\"/lapchart/{year}/{event}/{session}\", response_model=None)\n",
    "async def lap_chart(\n",
    "    year: int,\n",
    "    event: str | int,\n",
    "    session: str,\n",
    ") -> any:\n",
    "    ergast = Ergast()\n",
    "\n",
    "    race_names_df = ergast.get_race_schedule(season=year, result_type=\"pandas\")\n",
    "    event_number = race_names_df[race_names_df[\"raceName\"] == event][\"round\"].values[0]\n",
    "    drivers_df = ergast.get_driver_info(\n",
    "        season=year, round=event_number, result_type=\"pandas\"\n",
    "    )\n",
    "    laptimes_df = ergast.get_lap_times(\n",
    "        season=year, round=event_number, result_type=\"pandas\", limit=2000\n",
    "    ).content[0]\n",
    "    laptimes_df = pd.merge(laptimes_df, drivers_df, how=\"left\", on=\"driverId\")\n",
    "\n",
    "    results_df = ergast.get_race_results(\n",
    "        season=year, round=event_number, result_type=\"pandas\"\n",
    "    ).content[0]\n",
    "    results_df = results_df[[\"driverCode\", \"constructorName\"]]\n",
    "\n",
    "    # merge results_df on laptime_df\n",
    "    laptimes_df = pd.merge(laptimes_df, results_df, how=\"left\", on=\"driverCode\")\n",
    "\n",
    "    team_colors = utils.team_colors(year)\n",
    "    # add team_colors to laptimes_df\n",
    "    laptimes_df[\"fill\"] = laptimes_df[\"constructorName\"].map(team_colors)\n",
    "\n",
    "    #  rename number as x and position as y\n",
    "    laptimes_df.rename(\n",
    "        columns={\"number\": \"x\", \"position\": \"y\", \"driverCode\": \"id\"}, inplace=True\n",
    "    )\n",
    "\n",
    "    lap_chart_data = []\n",
    "\n",
    "    for driver in laptimes_df[\"id\"].unique():\n",
    "        data = laptimes_df[laptimes_df[\"id\"] == driver]\n",
    "        fill = data[\"fill\"].values[0]\n",
    "        data = data[[\"x\", \"y\"]]\n",
    "        data_dict = data.to_dict(orient=\"records\")\n",
    "        driver_dict = {\"id\": driver, \"fill\": fill, \"data\": data_dict}\n",
    "        # add this to all_data\n",
    "        lap_chart_data.append(driver_dict)\n",
    "\n",
    "    lap_chart_dict = {\"lapChartData\": lap_chart_data}\n",
    "\n",
    "    return lap_chart_dict\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/{year}/{event}/{session}\", response_model=None)\n",
    "async def session_drivers(year: int, event: str | int, session: str) -> any:\n",
    "    # get drivers available for a given year, event and session\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "\n",
    "    laps = f1session.laps\n",
    "    team_colors = utils.team_colors(year)\n",
    "    # add team_colors dict to laps on Team column\n",
    "    laps[\"color\"] = laps[\"Team\"].map(team_colors)\n",
    "\n",
    "    unique_drivers = laps[\"Driver\"].unique()\n",
    "\n",
    "    drivers = [\n",
    "        {\n",
    "            \"color\": laps[laps.Driver == driver].color.iloc[0],\n",
    "            \"label\": driver,\n",
    "            \"value\": driver,\n",
    "        }\n",
    "        for driver in unique_drivers\n",
    "    ]\n",
    "\n",
    "    return {\"drivers\": drivers}\n",
    "\n",
    "# select laps similar to select drivers select box\n",
    "@functools.cache\n",
    "@app.get(\"/laps/{year}/{event}/{session}\", response_model=None)\n",
    "async def get_driver_laps_data(year: int, event: str | int, session: str) -> any:\n",
    "    # get drivers available for a given year, event and session\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "    team_colors = utils.team_colors(year)\n",
    "    # add team_colors dict to laps on Team column\n",
    "    laps[\"color\"] = laps[\"Team\"].map(team_colors)\n",
    "\n",
    "    # combine Driver and LapNumber as a new column\n",
    "    laps[\"label\"] = (\n",
    "        laps[\"Driver\"]\n",
    "        + \"-\"\n",
    "        + laps[\"LapNumber\"].astype(int).astype(str)\n",
    "        + \"-\"\n",
    "        + str(year)\n",
    "        + \"-\"\n",
    "        + event\n",
    "        + \"-\"\n",
    "        + session\n",
    "    )\n",
    "    laps[\"value\"] = (\n",
    "        laps[\"Driver\"]\n",
    "        + \"-\"\n",
    "        + laps[\"LapNumber\"].astype(int).astype(str)\n",
    "        + \"-\"\n",
    "        + str(year)\n",
    "        + \"-\"\n",
    "        + event\n",
    "        + \"-\"\n",
    "        + session\n",
    "    )\n",
    "\n",
    "    laps = laps[[\"value\", \"label\", \"color\"]]\n",
    "\n",
    "    driver_laps_dict = laps.to_dict(\"records\")\n",
    "\n",
    "    return {\"laps\": driver_laps_dict}\n",
    "\n",
    "\n",
    "# format for chartData {\"chartData\":[{\"lapnumber\":1},{\n",
    "# \"VER\":91.564,\n",
    "# \"VER_compound\":\"SOFT\",\n",
    "# \"VER_compound_color\":\"#FF5733\",\n",
    "# \"lapnumber\":2\n",
    "# },{\"lapnumber\":3},{\"VER\":90.494,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":4},{\"lapnumber\":5},{\"VER\":90.062,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":6},{\"lapnumber\":7},{\"VER\":89.815,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":8},{\"VER\":105.248,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":9},{\"lapnumber\":10},{\"VER\":89.79,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":11},{\"VER\":145.101,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":12},{\"lapnumber\":13},{\"VER\":89.662,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":14},{\"lapnumber\":15},{\"VER\":89.617,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":16},{\"lapnumber\":17},{\"VER\":140.717,\"VER_compound\":\"SOFT\",\"VER_compound_color\":\"#FF5733\",\"lapnumber\":18}]}\n",
    "\n",
    "# @st.cache_data\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/{year}/{event}/{session}/{driver}\", response_model=None)\n",
    "async def laps_data(year: int, event: str | int, session: str, driver: str) -> any:\n",
    "    # get drivers available for a given year, event and session\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "    team_colors = utils.team_colors(year)\n",
    "    # add team_colors dict to laps on Team column\n",
    "\n",
    "    drivers = laps.Driver.unique()\n",
    "    # for each driver in drivers, get the Team column from laps and get the color from team_colors dict\n",
    "    drivers = [\n",
    "        {\n",
    "            \"color\": team_colors[laps[laps.Driver == driver].Team.iloc[0]],\n",
    "            \"label\": driver,\n",
    "            \"value\": driver,\n",
    "        }\n",
    "        for driver in drivers\n",
    "    ]\n",
    "\n",
    "    driver_laps = laps.pick_driver(driver)\n",
    "    driver_laps[\"LapTime\"] = driver_laps[\"LapTime\"].dt.total_seconds()\n",
    "    # remove rows where LapTime is null\n",
    "    driver_laps = driver_laps[driver_laps.LapTime.notnull()]\n",
    "    compound_colors = {\n",
    "        \"SOFT\": \"#FF0000\",\n",
    "        \"MEDIUM\": \"#FFFF00\",\n",
    "        \"HARD\": \"#FFFFFF\",\n",
    "        \"INTERMEDIATE\": \"#00FF00\",\n",
    "        \"WET\": \"#088cd0\",\n",
    "    }\n",
    "\n",
    "    driver_laps_data = []\n",
    "\n",
    "    for _, row in driver_laps.iterrows():\n",
    "        if row[\"LapTime\"] > 0:\n",
    "            lap = {\n",
    "                f\"{driver}\": row[\"LapTime\"],\n",
    "                f\"{driver}_compound\": row[\"Compound\"],\n",
    "                f\"{driver}_compound_color\": compound_colors[row[\"Compound\"]],\n",
    "                \"lapnumber\": row[\"LapNumber\"],\n",
    "            }\n",
    "        else:\n",
    "            lap = {\"lapnumber\": row[\"LapNumber\"]}\n",
    "\n",
    "        driver_laps_data.append(lap)\n",
    "\n",
    "    return {\"chartData\": driver_laps_data}\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/laptimes/{year}/{event}/{session}/{driver}\", response_model=None)\n",
    "async def get_laps_data(year: int, event: str | int, session: str, driver: str) -> any:\n",
    "    # get drivers available for a given year, event and session\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=False, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "    team_colors = utils.team_colors(year)\n",
    "    # add team_colors dict to laps on Team column\n",
    "\n",
    "    drivers = laps.Driver.unique()\n",
    "    # for each driver in drivers, get the Team column from laps and get the color from team_colors dict\n",
    "    drivers = [\n",
    "        {\n",
    "            \"color\": team_colors[laps[laps.Driver == driver].Team.iloc[0]],\n",
    "            \"label\": driver,\n",
    "            \"value\": driver,\n",
    "        }\n",
    "        for driver in drivers\n",
    "    ]\n",
    "\n",
    "    driver_laps = laps.pick_driver(driver)\n",
    "    driver_laps[\"LapTime\"] = driver_laps[\"LapTime\"].dt.total_seconds()\n",
    "    driver_laps = driver_laps[[\"Driver\", \"LapTime\", \"LapNumber\", \"Compound\"]]\n",
    "\n",
    "    # remove rows where LapTime is null\n",
    "    driver_laps = driver_laps[driver_laps.LapTime.notnull()]\n",
    "\n",
    "    driver_laps_dict = driver_laps.to_dict(\"records\")\n",
    "\n",
    "    return {\"chartData\": driver_laps_dict}\n",
    "\n",
    "\n",
    "# @st.cache_data\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "@app.get(\"/{year}/{event}/{session}/{driver}/{lap_number}\", response_model=None)\n",
    "async def telemetry_data(\n",
    "    year: int, event: str | int, session: str, driver: str, lap_number: int\n",
    ") -> any:\n",
    "    f1session = fastf1.get_session(year, event, session)\n",
    "    f1session.load(telemetry=True, weather=False, messages=False)\n",
    "    laps = f1session.laps\n",
    "\n",
    "    driver_laps = laps.pick_driver(driver)\n",
    "    driver_laps[\"LapTime\"] = driver_laps[\"LapTime\"].dt.total_seconds()\n",
    "\n",
    "    # get the telemetry for lap_number\n",
    "    selected_lap = driver_laps[driver_laps.LapNumber == lap_number]\n",
    "\n",
    "    telemetry = selected_lap.get_telemetry()\n",
    "\n",
    "    lon_acc, lat_acc = accelerations.compute_accelerations(telemetry)\n",
    "    telemetry[\"lon_acc\"] = lon_acc\n",
    "    telemetry[\"lat_acc\"] = lat_acc\n",
    "\n",
    "    telemetry[\"Time\"] = telemetry[\"Time\"].dt.total_seconds()\n",
    "\n",
    "    laptime = selected_lap.LapTime.values[0]\n",
    "    data_key = f\"{driver} - Lap {int(lap_number)} - {year} {session} [laptime]\"\n",
    "\n",
    "    telemetry[\"DRS\"] = telemetry[\"DRS\"].apply(lambda x: 1 if x in [10, 12, 14] else 0)\n",
    "\n",
    "    brake_tel = []\n",
    "    drs_tel = []\n",
    "    gear_tel = []\n",
    "    rpm_tel = []\n",
    "    speed_tel = []\n",
    "    throttle_tel = []\n",
    "    time_tel = []\n",
    "    track_map = []\n",
    "    lon_acc_tel = []\n",
    "    lat_acc_tel = []\n",
    "\n",
    "    for _, row in telemetry.iterrows():\n",
    "        brake = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"Brake\"],\n",
    "        }\n",
    "        brake_tel.append(brake)\n",
    "\n",
    "        drs = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"DRS\"],\n",
    "        }\n",
    "        drs_tel.append(drs)\n",
    "\n",
    "        gear = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"nGear\"],\n",
    "        }\n",
    "        gear_tel.append(gear)\n",
    "\n",
    "        rpm = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"RPM\"],\n",
    "        }\n",
    "        rpm_tel.append(rpm)\n",
    "\n",
    "        speed = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"Speed\"],\n",
    "        }\n",
    "        speed_tel.append(speed)\n",
    "\n",
    "        throttle = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"Throttle\"],\n",
    "        }\n",
    "        throttle_tel.append(throttle)\n",
    "\n",
    "        time = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"Time\"],\n",
    "        }\n",
    "        time_tel.append(time)\n",
    "\n",
    "        lon_acc = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"lon_acc\"],\n",
    "        }\n",
    "        lon_acc_tel.append(lon_acc)\n",
    "\n",
    "        lat_acc = {\n",
    "            \"x\": row[\"Distance\"],\n",
    "            \"y\": row[\"lat_acc\"],\n",
    "        }\n",
    "        lat_acc_tel.append(lat_acc)\n",
    "\n",
    "        track = {\n",
    "            \"x\": row[\"X\"],\n",
    "            \"y\": row[\"Y\"],\n",
    "        }\n",
    "        track_map.append(track)\n",
    "\n",
    "    telemetry_data = {\n",
    "        \"telemetryData\": {\n",
    "            \"brake\": brake_tel,\n",
    "            \"dataKey\": data_key,\n",
    "            \"drs\": drs_tel,\n",
    "            \"gear\": gear_tel,\n",
    "            \"rpm\": rpm_tel,\n",
    "            \"speed\": speed_tel,\n",
    "            \"throttle\": throttle_tel,\n",
    "            \"time\": time_tel,\n",
    "            \"lon_acc\": lon_acc_tel,\n",
    "            \"lat_acc\": lat_acc_tel,\n",
    "            \"trackMap\": track_map,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return telemetry_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
